{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P7dmcl30Uj6f",
        "outputId": "db5db682-e7e0-49ee-bd84-55d6d9272d28"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2.14.0\n"
          ]
        }
      ],
      "source": [
        "from __future__ import print_function\n",
        "\n",
        "import pennylane as qml\n",
        "import tensorflow as tf\n",
        "print(tf.__version__)\n",
        "import numpy as np\n",
        "from tensorflow.keras.datasets import cifar100\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KZpZ2VbQUj6k"
      },
      "outputs": [],
      "source": [
        "batch_size = 32\n",
        "num_classes = 10\n",
        "epochs = 50\n",
        "data_augmentation = True\n",
        "num_predictions = 20\n",
        "\n",
        "save_dir = os.path.join(os.getcwd(), 'saved_models')\n",
        "model_name = 'keras_cifar10_trained_model.h5'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l4dIBi7ZUj6m"
      },
      "source": [
        "## Loading data..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TbBYw0CaUj6n",
        "outputId": "3f28add8-0736-4d40-a94d-1007d60279b5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "x_train shape: (1000, 32, 32, 3)\n",
            "1000 train samples\n",
            "200 test samples\n"
          ]
        }
      ],
      "source": [
        "# The data, split between train and test sets:\n",
        "(x_train, y_train), (x_test, y_test) = cifar100.load_data()\n",
        "\n",
        "# Filter only classes 3 and 88\n",
        "class_indices_train = np.where((y_train[:, 0] == 3) | (y_train[:, 0] == 88))[0]\n",
        "class_indices_test = np.where((y_test[:, 0] == 3) | (y_test[:, 0] == 88))[0]\n",
        "\n",
        "x_train = x_train[class_indices_train]\n",
        "y_train = y_train[class_indices_train]\n",
        "\n",
        "x_test = x_test[class_indices_test]\n",
        "y_test = y_test[class_indices_test]\n",
        "\n",
        "# Map class labels to consecutive integers starting from 0\n",
        "class_mapping = {3: 0, 88: 1}\n",
        "y_train_mapped = np.vectorize(class_mapping.get)(y_train[:, 0])\n",
        "y_test_mapped = np.vectorize(class_mapping.get)(y_test[:, 0])\n",
        "\n",
        "# Print information about the new dataset\n",
        "print('x_train shape:', x_train.shape)\n",
        "print(x_train.shape[0], 'train samples')\n",
        "print(x_test.shape[0], 'test samples')\n",
        "\n",
        "# Convert class vectors to binary class matrices.\n",
        "num_classes = 2  # Number of classes (3 and 88)\n",
        "y_train = tf.keras.utils.to_categorical(y_train_mapped, num_classes)\n",
        "y_test = tf.keras.utils.to_categorical(y_test_mapped, num_classes)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kTM_FVoGUj6q"
      },
      "source": [
        "## Forward Propagation\n",
        "+ **Building a training model with `tf.keras`**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vmpLb1mrUj6r"
      },
      "outputs": [],
      "source": [
        "model = Sequential()\n",
        "model.add(Conv2D(32, (3, 3), padding='same',\n",
        "                 input_shape=x_train.shape[1:])) # feature map:(32x32x32)\n",
        "model.add(Activation('relu'))\n",
        "model.add(Conv2D(32, (3, 3)))  # feature map:(30x30x32)\n",
        "model.add(Activation('relu'))\n",
        "model.add(Conv2D(32, (3, 3)))  # feature map:(30x30x32)\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))  # feature map:(15x15x32)\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "model.add(Conv2D(64, (3, 3), padding='same'))  # feature map:(15x15x64)\n",
        "model.add(Activation('relu'))\n",
        "model.add(Conv2D(64, (3, 3), padding='same'))  # feature map:(15x15x64)\n",
        "model.add(Activation('relu'))\n",
        "model.add(Conv2D(64, (3, 3)))  # feature map:(13x13x64)\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))  # feature map:(6x6x64)\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "model.add(Flatten())  # (2304,)\n",
        "model.add(Dense(512))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(num_classes))\n",
        "model.add(Activation('softmax'))\n",
        "n_qubits = 2\n",
        "dev = qml.device(\"default.qubit\", wires=n_qubits)\n",
        "\n",
        "@qml.qnode(dev)\n",
        "def qnode(inputs, weights_0, weight_1):\n",
        "    qml.RX(inputs[0], wires=0)\n",
        "    qml.RX(inputs[1], wires=1)\n",
        "    qml.Rot(*weights_0, wires=0)\n",
        "    qml.RY(weight_1, wires=1)\n",
        "    qml.CNOT(wires=[0, 1])\n",
        "    return qml.expval(qml.PauliZ(0)), qml.expval(qml.PauliZ(1))\n",
        "\n",
        "weight_shapes = {\"weights_0\": 3, \"weight_1\": 1}\n",
        "qlayer = qml.qnn.KerasLayer(qnode, weight_shapes, output_dim=2)\n",
        "\n",
        "clayer = tf.keras.layers.Dense(2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "llQrfBlWUj6t"
      },
      "source": [
        "## Backpropagation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yzqpAWjHUj6u"
      },
      "outputs": [],
      "source": [
        "# initiate RMSprop optimizer\n",
        "opt = tf.keras.optimizers.legacy.RMSprop(learning_rate=0.0001, decay=1e-6)\n",
        "\n",
        "# Let's train the model using RMSprop\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=opt,\n",
        "              metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wgV05HWlUj6y"
      },
      "source": [
        "## Normalization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rV0oJYU1Uj6y"
      },
      "outputs": [],
      "source": [
        "x_train = x_train.astype('float32')\n",
        "x_test = x_test.astype('float32')\n",
        "x_train /= 255\n",
        "x_test /= 255"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MaFyLnANUj61"
      },
      "source": [
        "## Data Augmentation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9IfC3xz3j4Dx"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "os.environ['TF_GPU_ALLOCATOR'] = 'cuda_malloc_async'\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "slMZlaXEj4Dx",
        "outputId": "fe9d20c8-3c73-4d9a-f29b-42b6c12323e7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Physical devices cannot be modified after being initialized\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
        "if gpus:\n",
        "    try:\n",
        "        for gpu in gpus:\n",
        "            tf.config.experimental.set_memory_growth(gpu, True)\n",
        "    except RuntimeError as e:\n",
        "        print(e)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IDcEpsC1Uj61",
        "outputId": "6714728b-2fce-4c94-fd33-e42c19026e76",
        "scrolled": false
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using real-time data augmentation.\n",
            "Epoch 1/50\n",
            "250/250 [==============================] - 6s 16ms/step - loss: 0.6929 - accuracy: 0.5080 - val_loss: 0.6881 - val_accuracy: 0.5200\n",
            "Epoch 2/50\n",
            "250/250 [==============================] - 2s 8ms/step - loss: 0.6821 - accuracy: 0.6000 - val_loss: 0.6764 - val_accuracy: 0.7100\n",
            "Epoch 3/50\n",
            "250/250 [==============================] - 1s 6ms/step - loss: 0.6576 - accuracy: 0.7050 - val_loss: 0.6481 - val_accuracy: 0.6850\n",
            "Epoch 4/50\n",
            "250/250 [==============================] - 1s 6ms/step - loss: 0.6125 - accuracy: 0.7350 - val_loss: 0.6059 - val_accuracy: 0.7100\n",
            "Epoch 5/50\n",
            "250/250 [==============================] - 1s 6ms/step - loss: 0.5632 - accuracy: 0.7540 - val_loss: 0.5672 - val_accuracy: 0.7150\n",
            "Epoch 6/50\n",
            "250/250 [==============================] - 1s 6ms/step - loss: 0.5306 - accuracy: 0.7520 - val_loss: 0.5412 - val_accuracy: 0.7150\n",
            "Epoch 7/50\n",
            "250/250 [==============================] - 1s 6ms/step - loss: 0.4991 - accuracy: 0.7680 - val_loss: 0.5286 - val_accuracy: 0.7250\n",
            "Epoch 8/50\n",
            "250/250 [==============================] - 2s 8ms/step - loss: 0.4834 - accuracy: 0.7860 - val_loss: 0.5229 - val_accuracy: 0.7250\n",
            "Epoch 9/50\n",
            "250/250 [==============================] - 2s 9ms/step - loss: 0.4759 - accuracy: 0.7900 - val_loss: 0.5059 - val_accuracy: 0.7400\n",
            "Epoch 10/50\n",
            "250/250 [==============================] - 2s 8ms/step - loss: 0.4619 - accuracy: 0.7900 - val_loss: 0.4970 - val_accuracy: 0.7450\n",
            "Epoch 11/50\n",
            "250/250 [==============================] - 2s 7ms/step - loss: 0.4552 - accuracy: 0.7950 - val_loss: 0.4918 - val_accuracy: 0.7450\n",
            "Epoch 12/50\n",
            "250/250 [==============================] - 1s 6ms/step - loss: 0.4535 - accuracy: 0.7990 - val_loss: 0.4812 - val_accuracy: 0.7500\n",
            "Epoch 13/50\n",
            "250/250 [==============================] - 1s 6ms/step - loss: 0.4445 - accuracy: 0.7950 - val_loss: 0.4749 - val_accuracy: 0.7700\n",
            "Epoch 14/50\n",
            "250/250 [==============================] - 1s 6ms/step - loss: 0.4358 - accuracy: 0.8060 - val_loss: 0.4721 - val_accuracy: 0.7650\n",
            "Epoch 15/50\n",
            "250/250 [==============================] - 1s 6ms/step - loss: 0.4459 - accuracy: 0.7990 - val_loss: 0.4644 - val_accuracy: 0.7650\n",
            "Epoch 16/50\n",
            "250/250 [==============================] - 1s 6ms/step - loss: 0.4280 - accuracy: 0.8000 - val_loss: 0.4572 - val_accuracy: 0.7900\n",
            "Epoch 17/50\n",
            "250/250 [==============================] - 1s 6ms/step - loss: 0.4239 - accuracy: 0.8210 - val_loss: 0.4475 - val_accuracy: 0.7950\n",
            "Epoch 18/50\n",
            "250/250 [==============================] - 2s 8ms/step - loss: 0.4182 - accuracy: 0.8130 - val_loss: 0.4456 - val_accuracy: 0.7800\n",
            "Epoch 19/50\n",
            "250/250 [==============================] - 2s 8ms/step - loss: 0.4095 - accuracy: 0.8160 - val_loss: 0.4828 - val_accuracy: 0.7600\n",
            "Epoch 20/50\n",
            "250/250 [==============================] - 2s 7ms/step - loss: 0.4044 - accuracy: 0.8260 - val_loss: 0.4281 - val_accuracy: 0.8050\n",
            "Epoch 21/50\n",
            "250/250 [==============================] - 1s 6ms/step - loss: 0.4044 - accuracy: 0.8240 - val_loss: 0.4561 - val_accuracy: 0.7850\n",
            "Epoch 22/50\n",
            "250/250 [==============================] - 1s 5ms/step - loss: 0.3996 - accuracy: 0.8220 - val_loss: 0.4205 - val_accuracy: 0.8150\n",
            "Epoch 23/50\n",
            "250/250 [==============================] - 1s 6ms/step - loss: 0.4009 - accuracy: 0.8220 - val_loss: 0.4155 - val_accuracy: 0.8250\n",
            "Epoch 24/50\n",
            "250/250 [==============================] - 1s 6ms/step - loss: 0.3754 - accuracy: 0.8370 - val_loss: 0.4358 - val_accuracy: 0.7950\n",
            "Epoch 25/50\n",
            "250/250 [==============================] - 1s 6ms/step - loss: 0.3833 - accuracy: 0.8330 - val_loss: 0.3917 - val_accuracy: 0.8250\n",
            "Epoch 26/50\n",
            "250/250 [==============================] - 1s 6ms/step - loss: 0.3715 - accuracy: 0.8450 - val_loss: 0.3847 - val_accuracy: 0.8250\n",
            "Epoch 27/50\n",
            "250/250 [==============================] - 2s 8ms/step - loss: 0.3622 - accuracy: 0.8440 - val_loss: 0.3764 - val_accuracy: 0.8350\n",
            "Epoch 28/50\n",
            "250/250 [==============================] - 2s 8ms/step - loss: 0.3548 - accuracy: 0.8500 - val_loss: 0.3757 - val_accuracy: 0.8450\n",
            "Epoch 29/50\n",
            "250/250 [==============================] - 2s 6ms/step - loss: 0.3614 - accuracy: 0.8410 - val_loss: 0.3654 - val_accuracy: 0.8450\n",
            "Epoch 30/50\n",
            "250/250 [==============================] - 1s 6ms/step - loss: 0.3410 - accuracy: 0.8590 - val_loss: 0.3518 - val_accuracy: 0.8300\n",
            "Epoch 31/50\n",
            "250/250 [==============================] - 1s 6ms/step - loss: 0.3440 - accuracy: 0.8530 - val_loss: 0.3519 - val_accuracy: 0.8450\n",
            "Epoch 32/50\n",
            "250/250 [==============================] - 1s 6ms/step - loss: 0.3316 - accuracy: 0.8660 - val_loss: 0.4159 - val_accuracy: 0.7950\n",
            "Epoch 33/50\n",
            "250/250 [==============================] - 1s 6ms/step - loss: 0.3254 - accuracy: 0.8760 - val_loss: 0.3377 - val_accuracy: 0.8450\n",
            "Epoch 34/50\n",
            "250/250 [==============================] - 1s 6ms/step - loss: 0.3196 - accuracy: 0.8670 - val_loss: 0.3371 - val_accuracy: 0.8650\n",
            "Epoch 35/50\n",
            "250/250 [==============================] - 1s 6ms/step - loss: 0.3156 - accuracy: 0.8720 - val_loss: 0.3252 - val_accuracy: 0.8500\n",
            "Epoch 36/50\n",
            "250/250 [==============================] - 2s 8ms/step - loss: 0.2983 - accuracy: 0.8840 - val_loss: 0.3297 - val_accuracy: 0.8550\n",
            "Epoch 37/50\n",
            "250/250 [==============================] - 2s 9ms/step - loss: 0.3180 - accuracy: 0.8700 - val_loss: 0.2944 - val_accuracy: 0.8600\n",
            "Epoch 38/50\n",
            "250/250 [==============================] - 2s 7ms/step - loss: 0.2918 - accuracy: 0.8840 - val_loss: 0.2935 - val_accuracy: 0.8600\n",
            "Epoch 39/50\n",
            "250/250 [==============================] - 1s 6ms/step - loss: 0.2920 - accuracy: 0.8810 - val_loss: 0.2882 - val_accuracy: 0.8700\n",
            "Epoch 40/50\n",
            "250/250 [==============================] - 1s 6ms/step - loss: 0.2924 - accuracy: 0.8870 - val_loss: 0.2803 - val_accuracy: 0.8750\n",
            "Epoch 41/50\n",
            "250/250 [==============================] - 1s 6ms/step - loss: 0.2773 - accuracy: 0.8930 - val_loss: 0.2975 - val_accuracy: 0.8550\n",
            "Epoch 42/50\n",
            "250/250 [==============================] - 1s 6ms/step - loss: 0.2771 - accuracy: 0.8950 - val_loss: 0.2655 - val_accuracy: 0.8800\n",
            "Epoch 43/50\n",
            "250/250 [==============================] - 1s 6ms/step - loss: 0.2764 - accuracy: 0.8920 - val_loss: 0.2539 - val_accuracy: 0.8850\n",
            "Epoch 44/50\n",
            "250/250 [==============================] - 1s 6ms/step - loss: 0.2705 - accuracy: 0.8980 - val_loss: 0.2522 - val_accuracy: 0.8950\n",
            "Epoch 45/50\n",
            "250/250 [==============================] - 2s 8ms/step - loss: 0.2710 - accuracy: 0.8890 - val_loss: 0.2859 - val_accuracy: 0.8700\n",
            "Epoch 46/50\n",
            "250/250 [==============================] - 2s 8ms/step - loss: 0.2605 - accuracy: 0.8960 - val_loss: 0.2567 - val_accuracy: 0.8850\n",
            "Epoch 47/50\n",
            "250/250 [==============================] - 2s 6ms/step - loss: 0.2571 - accuracy: 0.8990 - val_loss: 0.3139 - val_accuracy: 0.8600\n",
            "Epoch 48/50\n",
            "250/250 [==============================] - 1s 6ms/step - loss: 0.2569 - accuracy: 0.9010 - val_loss: 0.2854 - val_accuracy: 0.8750\n",
            "Epoch 49/50\n",
            "250/250 [==============================] - 1s 6ms/step - loss: 0.2600 - accuracy: 0.9050 - val_loss: 0.2263 - val_accuracy: 0.9100\n",
            "Epoch 50/50\n",
            "250/250 [==============================] - 1s 6ms/step - loss: 0.2476 - accuracy: 0.9030 - val_loss: 0.2248 - val_accuracy: 0.9000\n"
          ]
        }
      ],
      "source": [
        "if not data_augmentation:\n",
        "    print('Not using data augmentation.')\n",
        "    model.fit(x_train, y_train,\n",
        "              batch_size=batch_size,\n",
        "              epochs=epochs,\n",
        "              validation_data=(x_test, y_test),\n",
        "              shuffle=True)\n",
        "else:\n",
        "    print('Using real-time data augmentation.')\n",
        "    # This will do preprocessing and realtime data augmentation:\n",
        "    datagen = ImageDataGenerator(\n",
        "        featurewise_center=False,  # set input mean to 0 over the dataset\n",
        "        samplewise_center=False,  # set each sample mean to 0\n",
        "        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
        "        samplewise_std_normalization=False,  # divide each input by its std\n",
        "        zca_whitening=False,  # apply ZCA whitening\n",
        "        zca_epsilon=1e-06,  # epsilon for ZCA whitening\n",
        "        rotation_range=0,  # randomly rotate images in the range (degrees, 0 to 180)\n",
        "        # randomly shift images horizontally (fraction of total width)\n",
        "        width_shift_range=0.1,\n",
        "        # randomly shift images vertically (fraction of total height)\n",
        "        height_shift_range=0.1,\n",
        "        shear_range=0.,  # set range for random shear\n",
        "        zoom_range=0.,  # set range for random zoom\n",
        "        channel_shift_range=0.,  # set range for random channel shifts\n",
        "        # set mode for filling points outside the input boundaries\n",
        "        fill_mode='nearest',\n",
        "        cval=0.,  # value used for fill_mode = \"constant\"\n",
        "        horizontal_flip=True,  # randomly flip images\n",
        "        vertical_flip=False,  # randomly flip images\n",
        "        # set rescaling factor (applied before any other transformation)\n",
        "        rescale=None,\n",
        "        # set function that will be applied on each input\n",
        "        preprocessing_function=None,\n",
        "        # image data format, either \"channels_first\" or \"channels_last\"\n",
        "        data_format=None,\n",
        "        # fraction of images reserved for validation (strictly between 0 and 1)\n",
        "        validation_split=0.0)\n",
        "\n",
        "    # Compute quantities required for feature-wise normalization\n",
        "    # (std, mean, and principal components if ZCA whitening is applied).\n",
        "    datagen.fit(x_train)\n",
        "\n",
        "    # Fit the model on the batches generated by datagen.flow().\n",
        "    model.fit(x_train, y_train, batch_size=4, epochs=epochs, validation_data=(x_test, y_test), workers=4)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IHChiTyFUj64"
      },
      "source": [
        "## Saving the model..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cKwN7UUeUj64",
        "outputId": "3141bfb1-d119-4e21-a415-b7bb1735edcf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saved trained model at /content/saved_models/keras_cifar10_trained_model.h5 \n"
          ]
        }
      ],
      "source": [
        "# Save model and weights\n",
        "if not os.path.isdir(save_dir):\n",
        "    os.makedirs(save_dir)\n",
        "model_path = os.path.join(save_dir, model_name)\n",
        "model.save(model_path)\n",
        "print('Saved trained model at %s ' % model_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VBLLhR2KUj67"
      },
      "source": [
        "## Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "no43mz5sUj67",
        "outputId": "1e859485-a9e8-4205-c19f-c896e8d4f44d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "7/7 - 0s - loss: 0.2248 - accuracy: 0.9000 - 184ms/epoch - 26ms/step\n",
            "Test loss: 0.22477000951766968\n",
            "Test accuracy: 0.8999999761581421\n"
          ]
        }
      ],
      "source": [
        "# Score trained model.\n",
        "scores = model.evaluate(x_test, y_test, verbose=2)\n",
        "print('Test loss:', scores[0])\n",
        "print('Test accuracy:', scores[1])"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
